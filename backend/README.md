# ğŸ“¦ Backend - Kubeflow Documentation RAG App

This is the **FastAPI backend** for the Kubeflow Documentation Retrieval-Augmented Generation (RAG) application. It powers documentation ingestion, embedding, vector storage, LLM integration, and real-time communication via WebSockets.

---

## ğŸš€ Features

- ğŸ“¥ **GitHub Documentation Ingestion** using Gitingest
- ğŸ§  **Embeddings** via Azure OpenAI text-ada-002 
- ğŸ—‚ï¸ **Vector Database** powered by Weaviate
- ğŸ¤– **LLM Chat Responses** using similarity search + Groq LLMs
- ğŸ”Œ **REST API** and **WebSocket** interfaces
- ğŸª„ **Modular Architecture** (Controllers, Services, Routes)

---

## ğŸ—‚ï¸ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI entrypoint
â”‚   â”œâ”€â”€ core/                    # Config, database & websocket manager
â”‚   â”œâ”€â”€ routes/                  # FastAPI route definitions
â”‚   â”œâ”€â”€ controllers/            # Request logic delegation
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â””â”€â”€ parsed_repositories/    # Saved docs after ingestion
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

The app uses **environment variables**, defined in a `.env` file.

### Example `.env` file:

```env
FRONTEND_URL=http://localhost:5173

# Weaviate Config
WEAVIATE_HOST=localhost
WEAVIATE_PORT=8080
WEAVIATE_API_KEY=your_api_key_if_any

# LLM & Embeddings
GROQ_API_KEY=your_groq_api_key
LLM_MODEL=llama-3.3-70b-versatile

# Azure OpenAI Config
OPENAI_API_KEY=your_openai_key
OPENAI_API_VERSION=2023-12-01-preview
OPENAI_AZURE_ENDPOINT=https://your-resource-name.openai.azure.com/
```

---

## ğŸ³ Running the Backend

### ğŸ§± With Docker

```bash
# From root directory
docker-compose up --build
```

### ğŸ’» Or manually (without Docker)

```bash
cd backend
poetry install
poetry run uvicorn app.main:app --reload
```

---

## ğŸ“¡ API Endpoints

### ğŸ§  LLM
| Method | Endpoint       | Description                      |
|--------|----------------|----------------------------------|
| POST   | `/llm`         | Get response from LLM            |

### ğŸ“„ Documentation
| Method | Endpoint              | Description                                |
|--------|-----------------------|--------------------------------------------|
| POST   | `/documentation`      | Ingest repo using Gitingest                |
| POST   | `/documentation/embed`| Chunk & embed repo content to Weaviate     |

### ğŸ“Š VectorDB (Weaviate)
| Method | Endpoint                   | Description                            |
|--------|----------------------------|----------------------------------------|
| GET    | `/vectordb/healthcheck`    | Check Weaviate connection              |
| POST   | `/vectordb/checkcollection`| Check if collection exists             |
| POST   | `/vectordb/collection`     | Create collection if missing           |
| POST   | `/vectordb`                | Add a document manually                |
| GET    | `/vectordb`                | Retrieve documents                     |
| DELETE | `/vectordb/{uuid}`         | Delete a document by UUID              |
| GET    | `/vectordb/similarity`     | Perform similarity search              |
| GET    | `/vectordb/count`          | Get total document count               |

### ğŸ”— Embedding
| Method | Endpoint       | Description                      |
|--------|----------------|----------------------------------|
| POST   | `/embeddings`  | Get embedding for custom text    |

### ğŸ”„ WebSocket
| Type   | Endpoint       | Description                      |
|--------|----------------|----------------------------------|
| WS     | `/ws/chat`     | Real-time LLM chat interface     |

---

## ğŸ” Technologies Used

- **FastAPI** â€“ Web framework
- **Langchain** â€“ Text splitting & prompt templating
- **Weaviate** â€“ Vector DB
- **Groq / Azure OpenAI** â€“ LLM & Embeddings
- **WebSocket** â€“ Real-time chat support
- **Poetry** â€“ Dependency management

---

